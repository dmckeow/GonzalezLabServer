#!/bin/bash
#SBATCH --job-name=test_job         # Job name
#SBATCH --output=test_job.%j.out    # Standard output log
#SBATCH --error=test_job.%j.err     # Standard error log
#SBATCH --partition=normal          # Partition: short, normal, long, marathon
#SBATCH --qos=normal                 # QoS: normal or big
#SBATCH --ntasks=1                   # Number of tasks (processes)
#SBATCH --cpus-per-task=16           # CPUs per task
#SBATCH --mem=64G                     # Memory per job
#SBATCH --time=00-02:00:00              # Max runtime (DD-HH:MM:SS)

# Optional: load modules or conda environments
module load python/3.11

# Your command(s) go here
echo "Job started on $(hostname) at $(date)"
python my_pipeline.py --input data/input.fasta --output results/output.txt
echo "Job finished at $(date)"
